{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic modelling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DHAYOE3YJEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593c70ac-f1cd-40ee-abf7-98a48144845a"
      },
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "  \n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "import re\n",
        "from gensim.models import TfidfModel, LsiModel, CoherenceModel, LdaModel\n",
        "import numpy as np\n",
        "from gensim.corpora import Dictionary\n",
        "from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAc5eZ9QYQ8r",
        "outputId": "c98d4bec-260e-4431-e905-5367a0b3e2a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcHPBuo4ZTs_"
      },
      "source": [
        "articles = pd.read_csv(\"/content/drive/My Drive/Topic modelling/Patents data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORHq90c8Ys6t"
      },
      "source": [
        "articles.drop(['patent_date','patent_number','patent_abstract'], axis=1, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Q2t3-qnKn3XR",
        "outputId": "6a083cca-7e3b-4ea2-fcd6-096ef23f8aea"
      },
      "source": [
        "articles"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"\"\"Barometer\"\" neuron for a neural network\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Electronic neural network for solving \"\"trave...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 layer liquid crystal neural network with out...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3-brain architecture for an intelligent decisi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3-brain architecture for an intelligent decisi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3517</th>\n",
              "      <td>Wireless communication system and method and s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3518</th>\n",
              "      <td>Wireless network coverage based on quality of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3519</th>\n",
              "      <td>Wireless network hybrid simulation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3520</th>\n",
              "      <td>Wireless neural network and a wireless neural ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3521</th>\n",
              "      <td>XML-based symbolic language and interpreter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3522 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text\n",
              "0           \"\"\"Barometer\"\" neuron for a neural network\"\n",
              "1     \"Electronic neural network for solving \"\"trave...\n",
              "2     3 layer liquid crystal neural network with out...\n",
              "3     3-brain architecture for an intelligent decisi...\n",
              "4     3-brain architecture for an intelligent decisi...\n",
              "...                                                 ...\n",
              "3517  Wireless communication system and method and s...\n",
              "3518  Wireless network coverage based on quality of ...\n",
              "3519                 Wireless network hybrid simulation\n",
              "3520  Wireless neural network and a wireless neural ...\n",
              "3521        XML-based symbolic language and interpreter\n",
              "\n",
              "[3522 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsQB8Eu5Zo94"
      },
      "source": [
        "def cleantext(text):\n",
        "    text = text.strip(punctuation).lower()\n",
        "    text = re.sub(r'[!?,.\\:;\\n\\t]+', '', text)\n",
        "    word= nltk.tokenize.word_tokenize(text)#tokenization\n",
        "    word = [w for w in word if w.isalpha()]# selecting only words\n",
        "    word = [w for w in word if w not in stopwords.words('english') and len(w) > 2]#removing stopwords \n",
        "    return word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiX6YMxxZywV"
      },
      "source": [
        "def tfidf_maker(articles,clean_method):\n",
        "    # creating a list of token of all the articles(documents)\n",
        "    token = []    \n",
        "    if clean_method==1:\n",
        "        #More cleaning with the help of lemmatizing words \n",
        "        for i in articles.index:\n",
        "            words = cleantext(articles.loc[i, 'text']) #calling basic function\n",
        "            wordnet = nltk.stem.WordNetLemmatizer() #Normalization using Lemmatization technique\n",
        "            lemmatized_words = [wordnet.lemmatize(w) for w in words] # keeping lemmatized words\n",
        "            token.append(lemmatized_words)             #appending to empty token list        \n",
        "        my_dict = Dictionary(token)  #Converting words into a dictonary Tokenization \n",
        "        return my_dict,token \n",
        "    elif clean_method==2:\n",
        "        #to exclude the top 10% of the most frequent words and words that appear less than 5 times in the documents\n",
        "        for i in articles.index:\n",
        "            words = cleantext(articles.loc[i, 'text'])\n",
        "            token.append(words) #appending to a empty token list\n",
        "        my_dict = Dictionary(token)  #Converting words into a dictonary Tokenization\n",
        "        #exclude the top 10% and words that appear less than 5 times\n",
        "        my_dict.filter_extremes(no_below=5, no_above=0.90)\n",
        "        return my_dict,token\n",
        "    elif clean_method==3:\n",
        "        #Limiting the word list with nouns\n",
        "        for i in articles.index:\n",
        "            words = cleantext(articles.loc[i, 'text'])\n",
        "            modified_text=' '.join([w for w in words])\n",
        "            blob_object = TextBlob(modified_text)\n",
        "            #Limiting the word list with nouns\n",
        "            word_list_nouns = [word for word,pos in blob_object.tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
        "            token.append(word_list_nouns) #apending a empty token list\n",
        "        my_dict = Dictionary(token)   #Converting words into a dictonary Tokenization\n",
        "        return my_dict,token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5TGCyrXZ3Ks"
      },
      "source": [
        "\n",
        "# Determining optimum number of topics using coherence values \n",
        "def maxCoherence(corpus, isLsi,my_dict,token):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    min_topics, max_topics, step = 1, 10, 1\n",
        "    for i in range(min_topics, max_topics, step):\n",
        "        if (isLsi) :\n",
        "            model = LsiModel(corpus, id2word=my_dict, num_topics=i)\n",
        "        else:\n",
        "            model = LdaModel(corpus, id2word=my_dict, num_topics=i)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=token, dictionary=my_dict, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "        print(coherence_values)\n",
        "    return coherence_values.index(max(coherence_values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpj9gEokZ6HD"
      },
      "source": [
        "# Get dominant topic and corresponding keywords for each article\n",
        "def getkeywords(model, corpus): \n",
        "    # Init output\n",
        "    topickeyword_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(model[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = model.show_topic(topic_num, topn=5)\n",
        "                #topn = 5 gives top 5 kwywords \n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                topickeyword_df = topickeyword_df.append(pd.Series([topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    return(topickeyword_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3sHrMM3aDYS"
      },
      "source": [
        "def models_method(clean_method):\n",
        "    #convert a list of words to bag of words\n",
        "    my_dict,token=tfidf_maker(articles,clean_method)\n",
        "    dtm = [my_dict.doc2bow(doc) for doc in token] #convert a list of words to bag of words\n",
        "    tfidf = TfidfModel(dtm) # TF-IDF Vectorization for the document term matrix\n",
        "    tfidf = tfidf[dtm]\n",
        "\n",
        "    # Gensim: LSI\n",
        "    lsi_model = LsiModel(corpus=tfidf, id2word=my_dict, num_topics=maxCoherence(tfidf,isLsi=True,my_dict = my_dict,token = token))\n",
        "\n",
        "    # Gensim: LDA\n",
        "    lda_model = LdaModel(corpus=tfidf, id2word=my_dict, num_topics=maxCoherence(tfidf,isLsi=False,my_dict = my_dict,token = token))\n",
        "    return lsi_model,lda_model,tfidf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrCyXkMaaJcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad61373d-a922-4b3f-c79e-0d785dff769e"
      },
      "source": [
        "from __future__ import division\n",
        "lsi_model_1,lda_model_1,tfidf = models_method(1)\n",
        "# add top 5 keywords for each model into the dataframe after vectorization \n",
        "articles['LSI Clean Keywords'] = getkeywords(model=lsi_model_1, corpus=tfidf)\n",
        "articles['LDA Clean Keywords'] = getkeywords(model=lda_model_1, corpus=tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1695129409900938]\n",
            "[0.1695129409900938, 0.22134925005534337]\n",
            "[0.1695129409900938, 0.22134925005534337, 0.2708191942654471]\n",
            "[0.1695129409900938, 0.22134925005534337, 0.2708191942654471, 0.2591903783406908]\n",
            "[0.1695129409900938, 0.22134925005534337, 0.2708191942654471, 0.2591903783406908, 0.3976668300772702]\n",
            "[0.1695129409900938, 0.22134925005534337, 0.2708191942654471, 0.2591903783406908, 0.3976668300772702, 0.36438783582002077]\n",
            "[0.1695129409900938, 0.22134925005534337, 0.2708191942654471, 0.2591903783406908, 0.3976668300772702, 0.36438783582002077, 0.34973964443469213]\n",
            "[0.1695129409900938, 0.22134925005534337, 0.2708191942654471, 0.2591903783406908, 0.3976668300772702, 0.36438783582002077, 0.34973964443469213, 0.323545224389016]\n",
            "[0.1695129409900938, 0.22134925005534337, 0.2708191942654471, 0.2591903783406908, 0.3976668300772702, 0.36438783582002077, 0.34973964443469213, 0.323545224389016, 0.36359178064829667]\n",
            "[0.14924432231144985]\n",
            "[0.14924432231144985, 0.19102963061667672]\n",
            "[0.14924432231144985, 0.19102963061667672, 0.24679914006274659]\n",
            "[0.14924432231144985, 0.19102963061667672, 0.24679914006274659, 0.27146381170162465]\n",
            "[0.14924432231144985, 0.19102963061667672, 0.24679914006274659, 0.27146381170162465, 0.2974514150690971]\n",
            "[0.14924432231144985, 0.19102963061667672, 0.24679914006274659, 0.27146381170162465, 0.2974514150690971, 0.3441666167002145]\n",
            "[0.14924432231144985, 0.19102963061667672, 0.24679914006274659, 0.27146381170162465, 0.2974514150690971, 0.3441666167002145, 0.3455307272875277]\n",
            "[0.14924432231144985, 0.19102963061667672, 0.24679914006274659, 0.27146381170162465, 0.2974514150690971, 0.3441666167002145, 0.3455307272875277, 0.36797644423242276]\n",
            "[0.14924432231144985, 0.19102963061667672, 0.24679914006274659, 0.27146381170162465, 0.2974514150690971, 0.3441666167002145, 0.3455307272875277, 0.36797644423242276, 0.3608358498518726]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "02AFzyRcaPP6",
        "outputId": "92ca5d29-1efb-4802-8595-7f1e0b909689"
      },
      "source": [
        "articles.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>LSI Clean Keywords</th>\n",
              "      <th>LDA Clean Keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"\"\"Barometer\"\" neuron for a neural network\"</td>\n",
              "      <td>recognition, pattern, speech, neural, network</td>\n",
              "      <td>network, neural, system, learning, method</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Electronic neural network for solving \"\"trave...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>system, neural, processing, network, process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 layer liquid crystal neural network with out...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>neural, network, system, speech, recognition</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                            LDA Clean Keywords\n",
              "0        \"\"\"Barometer\"\" neuron for a neural network\"  ...     network, neural, system, learning, method\n",
              "1  \"Electronic neural network for solving \"\"trave...  ...  system, neural, processing, network, process\n",
              "2  3 layer liquid crystal neural network with out...  ...  neural, network, system, speech, recognition\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj2AaWGKryq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2438e05d-d162-4007-af4c-61525d3e0e16"
      },
      "source": [
        "lsi_model_2,lda_model_2,tfidf = models_method(2)\n",
        "# add top 5 keywords for each model into the dataframe after vectorization \n",
        "articles['LSI Clean Keywords 2'] = getkeywords(model=lsi_model_2, corpus=tfidf)\n",
        "articles['LDA Clean Keywords 2'] = getkeywords(model=lda_model_2, corpus=tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1525778522171698]\n",
            "[0.1525778522171698, 0.31621061509413284]\n",
            "[0.1525778522171698, 0.31621061509413284, 0.23481758109714912]\n",
            "[0.1525778522171698, 0.31621061509413284, 0.23481758109714912, 0.24977782111065325]\n",
            "[0.1525778522171698, 0.31621061509413284, 0.23481758109714912, 0.24977782111065325, 0.41721847457632516]\n",
            "[0.1525778522171698, 0.31621061509413284, 0.23481758109714912, 0.24977782111065325, 0.41721847457632516, 0.42716544288355457]\n",
            "[0.1525778522171698, 0.31621061509413284, 0.23481758109714912, 0.24977782111065325, 0.41721847457632516, 0.42716544288355457, 0.2768968206321861]\n",
            "[0.1525778522171698, 0.31621061509413284, 0.23481758109714912, 0.24977782111065325, 0.41721847457632516, 0.42716544288355457, 0.2768968206321861, 0.36968739673372986]\n",
            "[0.1525778522171698, 0.31621061509413284, 0.23481758109714912, 0.24977782111065325, 0.41721847457632516, 0.42716544288355457, 0.2768968206321861, 0.36968739673372986, 0.3153517203277904]\n",
            "[0.12236802729907556]\n",
            "[0.12236802729907556, 0.20402482159835478]\n",
            "[0.12236802729907556, 0.20402482159835478, 0.21702098371264886]\n",
            "[0.12236802729907556, 0.20402482159835478, 0.21702098371264886, 0.24296760128239941]\n",
            "[0.12236802729907556, 0.20402482159835478, 0.21702098371264886, 0.24296760128239941, 0.2890106726670905]\n",
            "[0.12236802729907556, 0.20402482159835478, 0.21702098371264886, 0.24296760128239941, 0.2890106726670905, 0.2908250373423423]\n",
            "[0.12236802729907556, 0.20402482159835478, 0.21702098371264886, 0.24296760128239941, 0.2890106726670905, 0.2908250373423423, 0.2982882425961759]\n",
            "[0.12236802729907556, 0.20402482159835478, 0.21702098371264886, 0.24296760128239941, 0.2890106726670905, 0.2908250373423423, 0.2982882425961759, 0.321193083509046]\n",
            "[0.12236802729907556, 0.20402482159835478, 0.21702098371264886, 0.24296760128239941, 0.2890106726670905, 0.2908250373423423, 0.2982882425961759, 0.321193083509046, 0.3469799804732731]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "rIYiziOqsFWR",
        "outputId": "83a03944-ea5b-4f85-f003-8fdaf17a7f55"
      },
      "source": [
        "articles.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>LSI Clean Keywords</th>\n",
              "      <th>LDA Clean Keywords</th>\n",
              "      <th>LSI Clean Keywords 2</th>\n",
              "      <th>LDA Clean Keywords 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"\"\"Barometer\"\" neuron for a neural network\"</td>\n",
              "      <td>recognition, pattern, speech, neural, network</td>\n",
              "      <td>network, neural, system, learning, method</td>\n",
              "      <td>network, neural, system, method, using</td>\n",
              "      <td>recognition, network, neural, pattern, system</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Electronic neural network for solving \"\"trave...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>system, neural, processing, network, process</td>\n",
              "      <td>network, neural, system, method, using</td>\n",
              "      <td>networks, system, neural, network, method</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 layer liquid crystal neural network with out...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>neural, network, system, speech, recognition</td>\n",
              "      <td>network, neural, system, method, using</td>\n",
              "      <td>neural, network, circuit, optical, learning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                           LDA Clean Keywords 2\n",
              "0        \"\"\"Barometer\"\" neuron for a neural network\"  ...  recognition, network, neural, pattern, system\n",
              "1  \"Electronic neural network for solving \"\"trave...  ...      networks, system, neural, network, method\n",
              "2  3 layer liquid crystal neural network with out...  ...    neural, network, circuit, optical, learning\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxtKlSecsNNf",
        "outputId": "572df1ec-0a34-4bf8-9d1f-d770653e2f8d"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "from fractions import Fraction\n",
        "from __future__ import division\n",
        "lsi_model_3,lda_model_3,tfidf = models_method(3)\n",
        "# add top 5 keywords for each model into the dataframe after vectorization \n",
        "articles['LSI Clean Keywords 3'] = getkeywords(model=lsi_model_3, corpus=tfidf)\n",
        "articles['LDA Clean Keywords 3'] = getkeywords(model=lda_model_3, corpus=tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[0.26174636046263694]\n",
            "[0.26174636046263694, 0.4399516048795701]\n",
            "[0.26174636046263694, 0.4399516048795701, 0.3673018411455235]\n",
            "[0.26174636046263694, 0.4399516048795701, 0.3673018411455235, 0.5399177400432231]\n",
            "[0.26174636046263694, 0.4399516048795701, 0.3673018411455235, 0.5399177400432231, 0.48775682964990397]\n",
            "[0.26174636046263694, 0.4399516048795701, 0.3673018411455235, 0.5399177400432231, 0.48775682964990397, 0.548776632351767]\n",
            "[0.26174636046263694, 0.4399516048795701, 0.3673018411455235, 0.5399177400432231, 0.48775682964990397, 0.548776632351767, 0.5209840145863566]\n",
            "[0.26174636046263694, 0.4399516048795701, 0.3673018411455235, 0.5399177400432231, 0.48775682964990397, 0.548776632351767, 0.5209840145863566, 0.446321807762332]\n",
            "[0.26174636046263694, 0.4399516048795701, 0.3673018411455235, 0.5399177400432231, 0.48775682964990397, 0.548776632351767, 0.5209840145863566, 0.446321807762332, 0.47569458449193447]\n",
            "[0.3132454987420962]\n",
            "[0.3132454987420962, 0.29361179065779974]\n",
            "[0.3132454987420962, 0.29361179065779974, 0.37061227659510615]\n",
            "[0.3132454987420962, 0.29361179065779974, 0.37061227659510615, 0.37431613691035465]\n",
            "[0.3132454987420962, 0.29361179065779974, 0.37061227659510615, 0.37431613691035465, 0.43291871964234774]\n",
            "[0.3132454987420962, 0.29361179065779974, 0.37061227659510615, 0.37431613691035465, 0.43291871964234774, 0.4095400482437624]\n",
            "[0.3132454987420962, 0.29361179065779974, 0.37061227659510615, 0.37431613691035465, 0.43291871964234774, 0.4095400482437624, 0.42134561784673485]\n",
            "[0.3132454987420962, 0.29361179065779974, 0.37061227659510615, 0.37431613691035465, 0.43291871964234774, 0.4095400482437624, 0.42134561784673485, 0.44130895009596527]\n",
            "[0.3132454987420962, 0.29361179065779974, 0.37061227659510615, 0.37431613691035465, 0.43291871964234774, 0.4095400482437624, 0.42134561784673485, 0.44130895009596527, 0.4679757201803835]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "uKRWY3fpsUWm",
        "outputId": "15d894d8-f3e3-4475-b921-27b1b94450db"
      },
      "source": [
        "articles.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>LSI Clean Keywords</th>\n",
              "      <th>LDA Clean Keywords</th>\n",
              "      <th>LSI Clean Keywords 2</th>\n",
              "      <th>LDA Clean Keywords 2</th>\n",
              "      <th>LSI Clean Keywords 3</th>\n",
              "      <th>LDA Clean Keywords 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"\"\"Barometer\"\" neuron for a neural network\"</td>\n",
              "      <td>recognition, pattern, speech, neural, network</td>\n",
              "      <td>network, neural, system, learning, method</td>\n",
              "      <td>network, neural, system, method, using</td>\n",
              "      <td>recognition, network, neural, pattern, system</td>\n",
              "      <td>networks, network, control, recognition, method</td>\n",
              "      <td>recognition, process, network, system, method</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Electronic neural network for solving \"\"trave...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>system, neural, processing, network, process</td>\n",
              "      <td>network, neural, system, method, using</td>\n",
              "      <td>networks, system, neural, network, method</td>\n",
              "      <td>networks, network, control, recognition, method</td>\n",
              "      <td>recognition, process, network, system, method</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 layer liquid crystal neural network with out...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>neural, network, system, speech, recognition</td>\n",
              "      <td>network, neural, system, method, using</td>\n",
              "      <td>neural, network, circuit, optical, learning</td>\n",
              "      <td>networks, network, control, recognition, method</td>\n",
              "      <td>recognition, process, network, system, method</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                           LDA Clean Keywords 3\n",
              "0        \"\"\"Barometer\"\" neuron for a neural network\"  ...  recognition, process, network, system, method\n",
              "1  \"Electronic neural network for solving \"\"trave...  ...  recognition, process, network, system, method\n",
              "2  3 layer liquid crystal neural network with out...  ...  recognition, process, network, system, method\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRympWjMt0Av"
      },
      "source": [
        "#combining keywords from LSA , LDA after 3 ceaing methods into a new keyword column\n",
        "articles['keyword'] = articles[articles.columns[2:]].apply(\n",
        "    lambda x: ','.join(x.dropna().astype(str)),\n",
        "    axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tRfxINNuAqq"
      },
      "source": [
        "from collections import Counter \n",
        "for i in articles.index:\n",
        "    key_word = articles.loc[i, 'keyword']\n",
        "    key_word = key_word.split(',')\n",
        "    most_occur = Counter(key_word).most_common(5) \n",
        "    articles.loc[i, 'Top 5 Words'] = ','.join([word[0] for word in most_occur])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ7NgoVouD0L"
      },
      "source": [
        "articles = articles.drop(columns=['keyword']) #every keyword\n",
        "articles.to_csv('BBC_Keywords.csv',index=False,encoding='utf-8') #write to csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "id": "asOTKmsWuKMW",
        "outputId": "f6b4680c-8482-4402-facf-08980419e889"
      },
      "source": [
        "articles"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>LSI Clean Keywords</th>\n",
              "      <th>LDA Clean Keywords</th>\n",
              "      <th>LSI Clean Keywords 2</th>\n",
              "      <th>LDA Clean Keywords 2</th>\n",
              "      <th>LSI Clean Keywords 3</th>\n",
              "      <th>LDA Clean Keywords 3</th>\n",
              "      <th>Top 5 Words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"\"\"Barometer\"\" neuron for a neural network\"</td>\n",
              "      <td>recognition, pattern, speech, neural, network</td>\n",
              "      <td>network, neural, system, learning, method</td>\n",
              "      <td>network, neural, system, method, using</td>\n",
              "      <td>recognition, network, neural, pattern, system</td>\n",
              "      <td>networks, network, control, recognition, method</td>\n",
              "      <td>recognition, process, network, system, method</td>\n",
              "      <td>system, method, neural, network,network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Electronic neural network for solving \"\"trave...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>system, neural, processing, network, process</td>\n",
              "      <td>network, neural, system, method, using</td>\n",
              "      <td>networks, system, neural, network, method</td>\n",
              "      <td>networks, network, control, recognition, method</td>\n",
              "      <td>recognition, process, network, system, method</td>\n",
              "      <td>network, method, neural, system, process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 layer liquid crystal neural network with out...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>neural, network, system, speech, recognition</td>\n",
              "      <td>network, neural, system, method, using</td>\n",
              "      <td>neural, network, circuit, optical, learning</td>\n",
              "      <td>networks, network, control, recognition, method</td>\n",
              "      <td>recognition, process, network, system, method</td>\n",
              "      <td>network, system, method,neural, recognition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3-brain architecture for an intelligent decisi...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>network, neural, system, learning, method</td>\n",
              "      <td>control, system, image, processing, apparatus</td>\n",
              "      <td>network, neural, model, using, system</td>\n",
              "      <td>recognition, control, system, speech, network</td>\n",
              "      <td>networks, detection, system, images, method</td>\n",
              "      <td>system,network, neural, method, learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3-brain architecture for an intelligent decisi...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>network, neural, system, learning, method</td>\n",
              "      <td>control, system, image, processing, apparatus</td>\n",
              "      <td>network, neural, model, using, system</td>\n",
              "      <td>recognition, control, system, speech, network</td>\n",
              "      <td>networks, detection, system, images, method</td>\n",
              "      <td>system,network, neural, method, learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3517</th>\n",
              "      <td>Wireless communication system and method and s...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>pattern, recognition, system, network, neural</td>\n",
              "      <td>NaN</td>\n",
              "      <td>networks, system, neural, network, method</td>\n",
              "      <td>recognition, control, system, speech, network</td>\n",
              "      <td>system, image, systems, control, network</td>\n",
              "      <td>network, system, neural, control,pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3518</th>\n",
              "      <td>Wireless network coverage based on quality of ...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>neural, network, training, electronic, method</td>\n",
              "      <td>NaN</td>\n",
              "      <td>networks, system, neural, network, method</td>\n",
              "      <td>NaN</td>\n",
              "      <td>networks, detection, system, images, method</td>\n",
              "      <td>method, network,networks, system,neural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3519</th>\n",
              "      <td>Wireless network hybrid simulation</td>\n",
              "      <td>recognition, pattern, speech, neural, network</td>\n",
              "      <td>pattern, recognition, system, network, neural</td>\n",
              "      <td>NaN</td>\n",
              "      <td>network, neural, data, system, method</td>\n",
              "      <td>NaN</td>\n",
              "      <td>system, image, systems, control, network</td>\n",
              "      <td>system, network, neural,pattern, recognition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3520</th>\n",
              "      <td>Wireless neural network and a wireless neural ...</td>\n",
              "      <td>processing, image, network, neural, apparatus</td>\n",
              "      <td>learning, neural, network, system, method</td>\n",
              "      <td>NaN</td>\n",
              "      <td>networks, system, neural, network, method</td>\n",
              "      <td>NaN</td>\n",
              "      <td>system, image, systems, control, network</td>\n",
              "      <td>network, neural, system, method,learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3521</th>\n",
              "      <td>XML-based symbolic language and interpreter</td>\n",
              "      <td>NaN</td>\n",
              "      <td>neural, network, circuit, processor, system</td>\n",
              "      <td>NaN</td>\n",
              "      <td>neural, network, circuit, optical, learning</td>\n",
              "      <td>NaN</td>\n",
              "      <td>recognition, network, method, apparatus, system</td>\n",
              "      <td>network,neural, circuit, system, processor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3522 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ...                                    Top 5 Words\n",
              "0           \"\"\"Barometer\"\" neuron for a neural network\"  ...        system, method, neural, network,network\n",
              "1     \"Electronic neural network for solving \"\"trave...  ...       network, method, neural, system, process\n",
              "2     3 layer liquid crystal neural network with out...  ...    network, system, method,neural, recognition\n",
              "3     3-brain architecture for an intelligent decisi...  ...       system,network, neural, method, learning\n",
              "4     3-brain architecture for an intelligent decisi...  ...       system,network, neural, method, learning\n",
              "...                                                 ...  ...                                            ...\n",
              "3517  Wireless communication system and method and s...  ...       network, system, neural, control,pattern\n",
              "3518  Wireless network coverage based on quality of ...  ...        method, network,networks, system,neural\n",
              "3519                 Wireless network hybrid simulation  ...   system, network, neural,pattern, recognition\n",
              "3520  Wireless neural network and a wireless neural ...  ...       network, neural, system, method,learning\n",
              "3521        XML-based symbolic language and interpreter  ...     network,neural, circuit, system, processor\n",
              "\n",
              "[3522 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmW_5YcouMA_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}